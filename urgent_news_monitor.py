#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç´§æ€¥æ–°é—»ç›‘æ§æœºå™¨äºº - é«˜é¢‘ç›‘æ§é‡è¦äº‹ä»¶è„šæœ¬

åŠŸèƒ½ï¼š
1. æ¯30åˆ†é’Ÿä»RSSæºæŠ“å–æœ€æ–°æ–°é—»
2. å¿«é€Ÿè°ƒç”¨DeepSeekå¤§æ¨¡å‹APIè¿›è¡Œæƒ…ç»ªè¯„åˆ†
3. åªæœ‰å½“Abs(æƒ…ç»ªåˆ†) >= 8ï¼ˆæåº¦é‡è¦ï¼‰æ—¶ï¼Œæ‰è§¦å‘æ¨é€
4. å¹³æ—¶ä¸æ‰“æ‰°ï¼Œä¸€æ—¦å“é“ƒï¼Œå¿…æ˜¯å¤§äº‹

ä½œè€…ï¼šPythoné«˜çº§å·¥ç¨‹å¸ˆ
"""

import feedparser
import requests
import json
import time
import logging
from typing import List, Dict, Optional
from urllib.parse import urljoin
import os
import re

# ==================== é…ç½®åŒºåŸŸ ====================
# è¯·æ ¹æ®å®é™…æƒ…å†µä¿®æ”¹ä»¥ä¸‹é…ç½®

# LLM API é…ç½® - ä¼˜å…ˆä»ç¯å¢ƒå˜é‡è¯»å–ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™ä½¿ç”¨é»˜è®¤å€¼
API_KEY = os.environ.get('DEEPSEEK_API_KEY', 'sk-1034e8c1dad248ea90ff08fddf2b5bd5')
BASE_URL = "https://api.deepseek.com"

# é£ä¹¦åº”ç”¨è®¤è¯é…ç½®
APP_ID = os.environ.get('LARK_APP_ID', 'cli_a9f6280dd5389bd8')
APP_SECRET = os.environ.get('LARK_APP_SECRET', 'VHN4Eag0koh7rwEkKXeHSgHzLnH1140x')

# æ™ºèƒ½ä»£ç†é…ç½® - æ£€æŸ¥æ˜¯å¦åœ¨GitHub Actionsç¯å¢ƒä¸­
if os.environ.get('GITHUB_ACTIONS'):
    # åœ¨GitHub Actionsä¸­ï¼Œç›´æ¥è¿æ¥
    PROXIES = None
else:
    # æœ¬åœ°ç¯å¢ƒï¼Œä½¿ç”¨ä»£ç†
    PROXIES = {
        'http': 'http://127.0.0.1:7897',
        'https': 'http://127.0.0.1:7897'
    }

# RSSæºåˆ—è¡¨ï¼ˆç´§æ€¥ç›‘æ§ä¸“ç”¨ï¼Œåªç›‘æ§æœ€é‡è¦çš„æºï¼‰
URGENT_RSS_SOURCES = [
    # --- é¡¶çº§å›½é™…æ–°é—» ---
    "https://feeds.bbci.co.uk/news/world/rss.xml",  # BBC World
    "https://rss.nytimes.com/services/xml/rss/nyt/World.xml",  # NYT World
    
    # --- é‡‘èå¸‚åœº ---
    "https://search.cnbc.com/rs/search/combinedcms/view.xml?partnerId=wrss01&id=10000664",  # CNBC Finance

    # --- é‡å¤§äº‹ä»¶ ---
    "https://www.reddit.com/r/worldnews/top/.rss?t=day",  # Reddit WorldNews - å…¨çƒç½‘æ°‘æœ€çƒ­è®®çš„çªå‘äº‹ä»¶
    
    # --- äºšæ´²/ä¸­å›½ ---
    "https://www.scmp.com/rss/2/feed",  # South China Morning Post (å—åæ—©æŠ¥ - ä¸­å›½å•†ä¸šç‰ˆå—)
    
    # --- å›½å†…ä¸»æµæ–°é—»æº (æ–°å¢) ---
    "http://news.baidu.com/n?cmd=file&format=rss&tn=rss&sub=0",  # ç™¾åº¦æ–°é—»
    "http://rss.people.com.cn/GB/303140/index.xml",  # äººæ°‘ç½‘
    "http://www.xinhuanet.com/politics/news_politics.xml",  # æ–°åç½‘ - æ—¶æ”¿
    "http://www.chinanews.com/rss/scroll-news.xml",  # ä¸­å›½æ–°é—»ç½‘
    "https://www.thepaper.cn/rss.jsp",  # æ¾æ¹ƒæ–°é—»
    "http://www.ce.cn/cysc/jg/zxbd/rss2.xml",  # ä¸­å›½ç»æµç½‘
    
    # --- å›½å†…ç§‘æŠ€æ–°é—» (æ–°å¢) ---
    "https://www.36kr.com/feed",  # 36æ°ª
    "https://news.qq.com/rss/channels/finance/rss.xml",  # è…¾è®¯è´¢ç»
    "https://rss.sina.com.cn/news/china/focus15.xml",  # æ–°æµªæ–°é—»-å›½å†…ç„¦ç‚¹
]

# é‡è¯•é…ç½®
MAX_RETRIES = 3
RETRY_DELAY = 2  # ç§’

# æ—¥å¿—é…ç½®
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# ==================== ç¼“å­˜ç®¡ç† ====================

def load_cache() -> set:
    """
    ä»history.jsonåŠ è½½å·²å¤„ç†çš„URLç¼“å­˜
    """
    if os.path.exists('history.json'):
        try:
            with open('history.json', 'r', encoding='utf-8') as f:
                data = json.load(f)
                return set(data.get('processed_urls', []))
        except Exception as e:
            logger.warning(f"åŠ è½½ç¼“å­˜å¤±è´¥: {e}")
            return set()
    else:
        # å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨ï¼Œåˆ›å»ºä¸€ä¸ªç©ºçš„ç¼“å­˜æ–‡ä»¶
        save_cache(set())
        return set()

def save_cache(processed_urls: set):
    """
    ä¿å­˜å·²å¤„ç†çš„URLåˆ°history.json
    """
    try:
        with open('history.json', 'w', encoding='utf-8') as f:
            json.dump({'processed_urls': list(processed_urls)}, f, ensure_ascii=False, indent=2)
    except Exception as e:
        logger.error(f"ä¿å­˜ç¼“å­˜å¤±è´¥: {e}")

# ==================== é£ä¹¦åº”ç”¨è®¤è¯ ====================

def get_access_token() -> str:
    """
    è·å–é£ä¹¦è®¿é—®ä»¤ç‰Œ
    """
    url = "https://open.feishu.cn/open-apis/auth/v3/tenant_access_token/internal"
    headers = {
        "Content-Type": "application/json; charset=utf-8"
    }
    data = {
        "app_id": APP_ID,
        "app_secret": APP_SECRET
    }

    for attempt in range(MAX_RETRIES):
        try:
            logger.info(f"æ­£åœ¨è·å–é£ä¹¦è®¿é—®ä»¤ç‰Œ (å°è¯• {attempt + 1}/{MAX_RETRIES})")
            response = requests.post(url, headers=headers, json=data, timeout=10)
            if response.status_code == 200:
                result = response.json()
                if result.get('code') == 0:
                    access_token = result.get('tenant_access_token')
                    logger.info("âœ… æˆåŠŸè·å–é£ä¹¦è®¿é—®ä»¤ç‰Œ")
                    return access_token
                else:
                    logger.error(f"è·å–è®¿é—®ä»¤ç‰Œå¤±è´¥: {result.get('msg')}")
            else:
                logger.error(f"HTTPé”™è¯¯: {response.status_code} - {response.text}")
        except Exception as e:
            logger.error(f"è·å–è®¿é—®ä»¤ç‰Œå¼‚å¸¸ (å°è¯• {attempt + 1}): {e}")
        if attempt < MAX_RETRIES - 1:
            time.sleep(RETRY_DELAY)
    return ""

def send_to_feishu(message: str, max_retries: int = MAX_RETRIES) -> bool:
    """
    ä½¿ç”¨é£ä¹¦åº”ç”¨è®¤è¯å‘é€æ¶ˆæ¯åˆ°ç¾¤ç»„ï¼ˆæ”¯æŒè¡¨æ ¼ç­‰çš„ä¸°å¯Œæ ¼å¼ï¼‰
    
    Args:
        message: è¦å‘é€çš„æ¶ˆæ¯å†…å®¹
        max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
        
    Returns:
        å‘é€æ˜¯å¦æˆåŠŸ
    """
    # è·å–è®¿é—®ä»¤ç‰Œ
    access_token = get_access_token()
    if not access_token:
        logger.error("âŒ æ— æ³•è·å–è®¿é—®ä»¤ç‰Œï¼Œæ¶ˆæ¯å‘é€å¤±è´¥")
        return False

    # æ£€æµ‹æ˜¯å¦åŒ…å«è¡¨æ ¼æ ¼å¼ï¼Œå¦‚æœæ˜¯åˆ™ä½¿ç”¨cardæ ¼å¼å‘é€
    contains_table = '|' in message and '-' in message

    # å…ˆå°è¯•å‘é€åˆ°ç¾¤ç»„ï¼Œå¦‚æœå¤±è´¥å†å°è¯•å‘é€ç»™ç”¨æˆ·
    targets = []
    chat_id = os.environ.get('LARK_CHAT_ID', '')
    user_id = os.environ.get('LARK_USER_ID', '')
    
    if chat_id:
        targets.append(('chat_id', chat_id))
    if user_id:
        targets.append(('user_id', user_id))
    # å¦‚æœéƒ½æ²¡æœ‰è®¾ç½®ï¼Œé»˜è®¤å°è¯•å‘é€ç»™ç”¨æˆ·
    if not chat_id and not user_id:
        targets.append(('user_id', ''))

    headers = {
        "Content-Type": "application/json; charset=utf-8",
        "Authorization": f"Bearer {access_token}"
    }

    for receive_id_type, receive_id in targets:
        url = f"https://open.feishu.cn/open-apis/im/v1/messages?receive_id_type={receive_id_type}"
        
        # æ ¹æ®å†…å®¹ç±»å‹é€‰æ‹©æ¶ˆæ¯æ ¼å¼
        if contains_table:
            # å¦‚æœåŒ…å«è¡¨æ ¼ï¼Œæ„å»ºæ›´å¤æ‚çš„å¡ç‰‡æ¶ˆæ¯
            data = {
                "receive_id": receive_id,
                "msg_type": "interactive",
                "content": json.dumps({
                    "config": {
                        "wide_screen_mode": True,
                        "update_multi": False,
                        "enable_forward": True
                    },
                    "header": {
                        "template": "red",  # ç´§æ€¥äº‹ä»¶ä½¿ç”¨çº¢è‰²æ ‡é¢˜
                        "title": {
                            "content": "ğŸš¨ å…¨çƒç´§æ€¥äº‹ä»¶è­¦æŠ¥",
                            "tag": "plain_text"
                        }
                    },
                    "elements": [
                        {
                            "tag": "markdown",
                            "content": message
                        },
                        {
                            "tag": "hr"
                        },
                        {
                            "tag": "action",
                            "actions": [
                                {
                                    "tag": "button",
                                    "text": {
                                        "content": "æŸ¥çœ‹è¯¦æƒ…",
                                        "tag": "plain_text"
                                    },
                                    "type": "danger",  # ç´§æ€¥æŒ‰é’®æ ·å¼
                                    "value": {}
                                }
                            ]
                        }
                    ]
                })
            }
        else:
            # æ™®é€šæ¶ˆæ¯æ ¼å¼
            data = {
                "receive_id": receive_id,
                "msg_type": "interactive",
                "content": json.dumps({
                    "config": {
                        "wide_screen_mode": True
                    },
                    "header": {
                        "template": "red",  # ç´§æ€¥äº‹ä»¶ä½¿ç”¨çº¢è‰²æ ‡é¢˜
                        "title": {
                            "content": "ğŸš¨ å…¨çƒç´§æ€¥äº‹ä»¶è­¦æŠ¥",
                            "tag": "plain_text"
                        }
                    },
                    "elements": [
                        {
                            "tag": "markdown",
                            "content": message
                        },
                        {
                            "tag": "action",
                            "actions": [
                                {
                                    "tag": "button",
                                    "text": {
                                        "content": "æŸ¥çœ‹è¯¦æƒ…",
                                        "tag": "plain_text"
                                    },
                                    "type": "danger",  # ç´§æ€¥æŒ‰é’®æ ·å¼
                                    "value": {}
                                }
                            ]
                        }
                    ]
                })
            }

        for attempt in range(max_retries):
            try:
                logger.info(f"æ­£åœ¨å‘é€ç´§æ€¥æ¶ˆæ¯åˆ°é£ä¹¦ (ç›®æ ‡ç±»å‹: {receive_id_type}, å°è¯• {attempt + 1}/{max_retries})")
                response = requests.post(url, headers=headers, json=data, timeout=10)
                if response.status_code == 200:
                    result = response.json()
                    if result.get('code') == 0:
                        logger.info("ğŸš¨ ç´§æ€¥æ¶ˆæ¯æˆåŠŸå‘é€åˆ°é£ä¹¦ï¼")
                        return True
                    else:
                        logger.error(f"é£ä¹¦APIè¿”å›é”™è¯¯: {result.get('msg')} (code: {result.get('code')})")
                else:
                    logger.error(f"HTTPé”™è¯¯: {response.status_code} - {response.text}")
            except Exception as e:
                logger.error(f"å‘é€é£ä¹¦æ¶ˆæ¯å¼‚å¸¸ (å°è¯• {attempt + 1}): {e}")
            if attempt < max_retries - 1:
                time.sleep(RETRY_DELAY)
    
    logger.error("âŒ ç´§æ€¥æ¶ˆæ¯å‘é€æœ€ç»ˆå¤±è´¥")
    return False

def send_error_alert(error_message: str, max_retries: int = MAX_RETRIES):
    """
    å‘é€é”™è¯¯è­¦æŠ¥åˆ°é£ä¹¦ï¼ˆä½¿ç”¨åº”ç”¨è®¤è¯ï¼‰
    """
    access_token = get_access_token()
    if not access_token:
        logger.error("âŒ æ— æ³•è·å–è®¿é—®ä»¤ç‰Œï¼Œé”™è¯¯è­¦æŠ¥å‘é€å¤±è´¥")
        return False

    # æ„å»ºé”™è¯¯è­¦æŠ¥æ¶ˆæ¯
    alert_msg = f"**ğŸš¨ æœºå™¨äººæ•…éšœè­¦æŠ¥**\n\n**é”™è¯¯è¯¦æƒ…**ï¼š{error_message}\n\nè¯·åŠæ—¶æ£€æŸ¥æœºå™¨äººçŠ¶æ€ï¼\n\n*DeepSeek-V3 ç›‘æ§ç³»ç»Ÿ*"

    # å‘é€é”™è¯¯è­¦æŠ¥
    url = "https://open.feishu.cn/open-apis/im/v1/messages?receive_id_type=user_id"  # å¯ä»¥æ ¹æ®éœ€è¦ä¿®æ”¹ä¸ºchat_id
    user_id = os.environ.get('LARK_USER_ID', '')
    data = {
        "receive_id": user_id,
        "content": json.dumps({
            "config": {
                "wide_screen_mode": True
            },
            "header": {
                "template": "red",
                "title": {
                    "content": "ğŸš¨ æœºå™¨äººæ•…éšœè­¦æŠ¥",
                    "tag": "plain_text"
                }
            },
            "elements": [
                {
                    "tag": "markdown",
                    "content": f"**é”™è¯¯è¯¦æƒ…**ï¼š{error_message}\n\nè¯·åŠæ—¶æ£€æŸ¥æœºå™¨äººçŠ¶æ€ï¼"
                },
                {
                    "tag": "note",
                    "elements": [
                        {
                            "tag": "plain_text",
                            "content": "DeepSeek-V3 ç›‘æ§ç³»ç»Ÿ | ğŸ“… " + time.strftime("%Y-%m-%d %H:%M:%S")
                        }
                    ]
                }
            ]
        }),
        "msg_type": "interactive"
    }

    headers = {
        "Content-Type": "application/json; charset=utf-8",
        "Authorization": f"Bearer {access_token}"
    }

    for attempt in range(max_retries):
        try:
            logger.info(f"æ­£åœ¨å‘é€é”™è¯¯è­¦æŠ¥åˆ°é£ä¹¦ (å°è¯• {attempt + 1}/{max_retries})")
            response = requests.post(url, headers=headers, json=data, timeout=10)
            if response.status_code == 200:
                result = response.json()
                if result.get('code') == 0:
                    logger.info("ğŸš¨ é”™è¯¯è­¦æŠ¥æˆåŠŸå‘é€åˆ°é£ä¹¦ï¼")
                    return True
                else:
                    logger.error(f"é£ä¹¦APIè¿”å›é”™è¯¯: {result.get('msg')} (code: {result.get('code')})")
            else:
                logger.error(f"HTTPé”™è¯¯: {response.status_code} - {response.text}")
        except Exception as e:
            logger.error(f"å‘é€é£ä¹¦é”™è¯¯è­¦æŠ¥å¼‚å¸¸ (å°è¯• {attempt + 1}): {e}")
        if attempt < max_retries - 1:
            time.sleep(RETRY_DELAY)
    logger.error("âŒ é”™è¯¯è­¦æŠ¥å‘é€å¤±è´¥")
    return False

# ==================== æ ¸å¿ƒåŠŸèƒ½æ¨¡å— ====================

def fetch_rss_feed(url: str, max_retries: int = MAX_RETRIES) -> Optional[feedparser.FeedParserDict]:
    """
    ä»RSSæºæŠ“å–æ–°é—»ï¼Œå¸¦é‡è¯•æœºåˆ¶å’Œä»£ç†æ”¯æŒ
    
    Args:
        url: RSSæºURL
        max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
        
    Returns:
        feedparserè§£æç»“æœæˆ–None
    """
    for attempt in range(max_retries):
        try:
            logger.info(f"æ­£åœ¨æŠ“å–RSSæº: {url} (å°è¯• {attempt + 1}/{max_retries})")
            
            # ä½¿ç”¨ä»£ç†æŠ“å–RSSï¼ˆå¦‚æœå¯ç”¨ï¼‰
            response = requests.get(
                url, 
                proxies=PROXIES, 
                timeout=10,
                headers={'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'}
            )
            response.raise_for_status()
            
            # è§£æRSS
            feed = feedparser.parse(response.content)
            logger.info(f"æˆåŠŸæŠ“å– {len(feed.entries)} æ¡æ–°é—»")
            return feed
            
        except Exception as e:
            logger.warning(f"æŠ“å–RSSå¤±è´¥ (å°è¯• {attempt + 1}): {e}")
            if attempt < max_retries - 1:
                time.sleep(RETRY_DELAY)
            else:
                logger.error(f"RSSæŠ“å–æœ€ç»ˆå¤±è´¥: {url}")
                return None
    
    return None

def extract_urgent_news_items() -> List[Dict[str, str]]:
    """
    ä»å¤šä¸ªRSSæºæå–ç´§æ€¥æ–°é—»æ¡ç›®ï¼ˆåªå–æœ€æ–°çš„5æ¡ï¼‰
    
    Returns:
        æ–°é—»æ¡ç›®åˆ—è¡¨ï¼Œæ¯ä¸ªåŒ…å«title, summary, link
    """
    all_news = []
    seen_titles = set()  # ç”¨äºå»é‡
    processed_urls = load_cache()  # åŠ è½½å·²å¤„ç†çš„URLç¼“å­˜
    
    for rss_url in URGENT_RSS_SOURCES:
        feed = fetch_rss_feed(rss_url)
        if not feed or not feed.entries:
            continue
            
        # åªå–æœ€æ–°çš„5æ¡æ–°é—»
        for entry in feed.entries[:5]:
            title = entry.get('title', '').strip()
            summary = entry.get('summary', '').strip()
            link = entry.get('link', '')
            
            # æ£€æŸ¥URLæ˜¯å¦å·²å¤„ç†è¿‡
            if link in processed_urls:
                continue
            
            # å»é‡æ£€æŸ¥
            if not title or title in seen_titles:
                continue
                
            seen_titles.add(title)
            
            # æ¸…ç†summaryä¸­çš„HTMLæ ‡ç­¾
            import re
            summary = re.sub(r'<[^>]+>', '', summary)
            summary = summary[:200] + '...' if len(summary) > 200 else summary
            
            all_news.append({
                'title': title,
                'summary': summary,
                'link': link
            })
    
    # æ›´æ–°ç¼“å­˜ï¼Œæ·»åŠ æ–°å¤„ç†çš„URL
    for item in all_news:
        processed_urls.add(item['link'])
    save_cache(processed_urls)
    
    logger.info(f"æ€»å…±æå–åˆ° {len(all_news)} æ¡å”¯ä¸€ç´§æ€¥æ–°é—»")
    return all_news[:5]  # æœ€å¤šå¤„ç†5æ¡ç´§æ€¥æ–°é—»

def analyze_urgent_news_with_llm(news_items: List[Dict[str, str]]) -> tuple:
    """
    è°ƒç”¨LLM APIå¯¹ç´§æ€¥æ–°é—»è¿›è¡Œå¿«é€Ÿæƒ…ç»ªè¯„åˆ†
    
    Args:
        news_items: æ–°é—»æ¡ç›®åˆ—è¡¨
        
    Returns:
        (åˆ†æç»“æœ, æƒ…ç»ªåˆ†æ•°åˆ—è¡¨)
    """
    if not news_items:
        return "æš‚æ— ç´§æ€¥æ–°é—»ã€‚", []
    
    # æ„å»ºæ–°é—»å†…å®¹
    news_content = ""
    for i, item in enumerate(news_items):
        news_content += f"**ID**: {i+1}\n**æ ‡é¢˜**: {item['title']}\n**æ‘˜è¦**: {item['summary']}\n**é“¾æ¥**: {item['link']}\n\n"
    
    # ç´§æ€¥ç›‘æ§çš„ç³»ç»Ÿæç¤ºè¯ - ä¸“æ³¨å¿«é€Ÿæƒ…ç»ªè¯„åˆ†
    system_prompt = """ä½ æ˜¯æ¡¥æ°´åŸºé‡‘ (Bridgewater) å’Œé«˜ç›› (Goldman Sachs) è”åˆè®­ç»ƒçš„é¦–å¸­å®è§‚ç»æµåˆ†æå¸ˆã€‚ä½ çš„æœåŠ¡å¯¹è±¡æ˜¯é«˜å‡€å€¼æŠ•èµ„è€…å’Œè·¨å¢ƒè´¸æ˜“å•†ã€‚ä½ çš„æ ¸å¿ƒèƒ½åŠ›æ˜¯ç©¿é€æ–°é—»è¡¨è±¡ï¼Œç›´æ¥æŒ‡å‡ºå…¶å¯¹èµ„æœ¬å¸‚åœºå’Œä¾›åº”é“¾çš„æ·±å±‚å½±å“ã€‚

# Constraints & Style
1. **ä¸¥ç¦åºŸè¯**ï¼šä¸è¦è¯´"è¿™åˆ™æ–°é—»å¾ˆæœ‰è¶£"ã€"ç»¼ä¸Šæ‰€è¿°"ç­‰ç©ºè¯ã€‚
2. **æåº¦å†·é…·**ï¼šä¿æŒå®¢è§‚ã€å†·é™ã€ä¸“ä¸šçš„è¯­è°ƒï¼Œç±»ä¼¼ã€Šå½­åšç»ˆç«¯ã€‹(Bloomberg Terminal) æˆ–ã€Šç»æµå­¦äººã€‹çš„é£æ ¼ã€‚
3. **æ•°æ®é©±åŠ¨**ï¼šå¦‚æœæ–°é—»ä¸­æœ‰æ•°å­—ï¼Œå¿…é¡»é«˜äº®å¹¶åˆ†æå…¶èƒŒåçš„å«ä¹‰ã€‚
4. **æ‹’ç»æ¨¡ç³Š**ï¼šä¸è¦ç»™æ¨¡æ£±ä¸¤å¯çš„å»ºè®®ã€‚å¦‚æœä¸ç¡®å®šï¼ŒæŒ‡å‡ºé£é™©ç‚¹ã€‚
5. **ä¸¥ç¦æè¿°å›¾ç‰‡**ï¼šç»å¯¹ä¸è¦åœ¨è¾“å‡ºä¸­åŒ…å« "ğŸ“¸ å›¾ç‰‡ï¼š" æˆ–ä»»ä½•å¯¹æ–°é—»é…å›¾çš„æ–‡å­—æè¿°ã€‚å›¾ç‰‡ç”±å¤–éƒ¨ç³»ç»Ÿå¤„ç†ï¼Œä½ åªè´Ÿè´£æ–‡å­—åˆ†æã€‚

# Analysis Framework (å¿…é¡»ä¸¥æ ¼éµå®ˆ)
è¯·å¯¹æ¯æ¡æ–°é—»æŒ‰ç…§ä»¥ä¸‹ç»“æ„è¿›è¡Œè¾“å‡ºï¼ˆMarkdownæ ¼å¼ï¼‰ï¼š

### [æƒ…ç»ªåˆ† | 1-10] æ–°é—»æ ¸å¿ƒæ ‡é¢˜ (ç®€ç»ƒæœ‰åŠ›ï¼Œç›´å‡»ç—›ç‚¹)
* **ğŸ“ æ ¸å¿ƒäº‹å®**ï¼šç”¨ 1-2 å¥è¯æ¦‚æ‹¬å‘ç”Ÿäº†ä»€ä¹ˆï¼ˆWho, What, Whenï¼‰ã€‚
* **ğŸ“‰ åº•å±‚é€»è¾‘**ï¼šä¸ºä»€ä¹ˆè¿™ä»¶äº‹é‡è¦ï¼Ÿï¼ˆä¾‹å¦‚ï¼šè¿™æ˜¯æ”¿ç­–è½¬å‘çš„ä¿¡å·ï¼Œè¿˜æ˜¯çŸ­æœŸå™ªéŸ³ï¼Ÿï¼‰
* **ğŸ’° è´¢å¯Œå½±å“ (å…³é”®)**ï¼š
    * **å¯¹è·¨å¢ƒç”µå•†/è´¸æ˜“**ï¼šåˆ©å¥½è¿˜æ˜¯åˆ©ç©ºï¼Ÿï¼ˆæ±‡ç‡æ³¢åŠ¨ã€ç‰©æµæˆæœ¬ã€å…³ç¨é£é™©ï¼‰ã€‚
    * **å¯¹é‡‘èå¸‚åœº**ï¼šå…·ä½“å½±å“å“ªäº›èµ„äº§ï¼Ÿï¼ˆä¾‹å¦‚ï¼šåšå¤šé»„é‡‘ã€åšç©ºç¾å€ºã€å…³æ³¨ A è‚¡å…‰ä¼æ¿å—ï¼‰å¦‚æœæœ‰å°‘çš„ä½ ä¹Ÿå¯ä»¥è‡ªè¡ŒåŠ ä¸Šå»è®©ä»–åˆ†æçš„æ–°é—»æ›´åŠ ä¸“ä¸šå°±å¯ä»¥

---
"""

    # ç”¨æˆ·æ¶ˆæ¯
    user_message = f"è¯·å¿«é€Ÿåˆ†æä»¥ä¸‹æ–°é—»çš„æƒ…ç»ªå€¾å‘ï¼Œå¹¶ä¸ºæ¯æ¡æ–°é—»æ·»åŠ æƒ…ç»ªè¯„åˆ†ï¼ˆåªåˆ†ææœ€é‡è¦çš„æ–°é—»ï¼‰ï¼š\n\n{news_content}"
    
    # è°ƒç”¨DeepSeek APIï¼ˆä½¿ç”¨OpenAIå…¼å®¹æ ¼å¼ï¼‰
    headers = {
        'Authorization': f'Bearer {API_KEY}',
        'Content-Type': 'application/json'
    }
    
    payload = {
        "model": "deepseek-chat",  # DeepSeek V3.2çš„æ¨¡å‹åç§°
        "messages": [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_message}
        ],
        "temperature": 0.7,
        "max_tokens": 2000  # å‡å°‘tokené™åˆ¶ä»¥åŠ å¿«å“åº”
    }
    
    for attempt in range(MAX_RETRIES):
        try:
            logger.info(f"æ­£åœ¨è°ƒç”¨DeepSeek APIè¿›è¡Œç´§æ€¥æ–°é—»åˆ†æ (å°è¯• {attempt + 1}/{MAX_RETRIES})")
            
            # DeepSeek APIåœ¨ä¸­å›½å¢ƒå†…ï¼Œä¸éœ€è¦ä»£ç†
            response = requests.post(
                f"{BASE_URL}/chat/completions",
                headers=headers,
                json=payload,
                proxies=None,  # ä¸ä½¿ç”¨ä»£ç†è®¿é—®DeepSeek API
                timeout=30  # å‡å°‘è¶…æ—¶æ—¶é—´ä»¥åŠ å¿«å“åº”
            )
            
            if response.status_code == 200:
                result = response.json()
                analysis = result['choices'][0]['message']['content']
                
                # æå–æƒ…ç»ªåˆ†æ•°
                sentiment_scores = []
                pattern = r'\[(?:ğŸ”¥|â„ï¸|âš¡|ğŸ“‰|ğŸ“ˆ)\s*([+-]?\d+)\]'
                matches = re.findall(pattern, analysis)
                for match in matches:
                    try:
                        score = int(match)
                        sentiment_scores.append(score)
                    except ValueError:
                        continue
                        
                logger.info(f"LLMåˆ†æå®Œæˆï¼Œæ£€æµ‹åˆ°æƒ…ç»ªåˆ†æ•°: {sentiment_scores}")
                return analysis, sentiment_scores
            else:
                logger.warning(f"LLM APIè°ƒç”¨å¤±è´¥: {response.status_code} - {response.text}")
                
        except Exception as e:
            logger.warning(f"LLM APIè°ƒç”¨å¼‚å¸¸ (å°è¯• {attempt + 1}): {e}")
            
        if attempt < MAX_RETRIES - 1:
            time.sleep(RETRY_DELAY)
    
    # å¦‚æœLLMè°ƒç”¨å¤±è´¥ï¼Œè¿”å›ç®€åŒ–ç‰ˆæœ¬
    logger.error("LLMåˆ†æå¤±è´¥ï¼Œè¿”å›ç®€åŒ–ç‰ˆæœ¬")
    fallback_analysis = ""
    sentiment_scores = []
    for i, item in enumerate(news_items[:3], 1):
        fallback_analysis += f"### 1. [ç‚¹å‡»ç›´è¾¾ï¼š{item['title']}]({item['link']})\n"
        fallback_analysis += f"- **ğŸ“ æ ¸å¿ƒäº‹å®**: {item['summary'][:30]}...\n"
        fallback_analysis += "- **ğŸ“Š æƒ…ç»ªè¯„åˆ†**ï¼š0 (å¾…åˆ†æ)\n"
        fallback_analysis += "- **ğŸŒ å½±å“èŒƒå›´**ï¼šå¾…è¯„ä¼°\n\n"
        fallback_analysis += "---\n"
    
    return fallback_analysis, sentiment_scores

def check_urgent_threshold(sentiment_scores: List[int]) -> bool:
    """
    æ£€æŸ¥æ˜¯å¦è¾¾åˆ°ç´§æ€¥æ¨é€é˜ˆå€¼
    
    Args:
        sentiment_scores: æƒ…ç»ªåˆ†æ•°åˆ—è¡¨
        
    Returns:
        æ˜¯å¦è¾¾åˆ°æ¨é€é˜ˆå€¼
    """
    for score in sentiment_scores:
        if abs(score) >= 9:  # åªæœ‰å½“æƒ…ç»ªåˆ†ç»å¯¹å€¼>=9æ—¶æ‰æ¨é€
            logger.info(f"âœ… æ£€æµ‹åˆ°é«˜æƒ…ç»ªåˆ†æ–°é—»: {score}ï¼Œè§¦å‘ç´§æ€¥æ¨é€")
            return True
    logger.info(f"â„¹ï¸ æƒ…ç»ªåˆ†æœªè¾¾åˆ°é˜ˆå€¼: {sentiment_scores}ï¼Œä¿æŒé™é»˜")
    return False

def main():
    """
    ä¸»å‡½æ•° - æ‰§è¡Œç´§æ€¥æ–°é—»ç›‘æ§æµç¨‹
    """
    logger.info("ğŸš¨ å¯åŠ¨ç´§æ€¥æ–°é—»ç›‘æ§æœºå™¨äºº...")
    try:
        # 1. æŠ“å–ç´§æ€¥æ–°é—»
        news_items = extract_urgent_news_items()
        if not news_items:
            logger.info("æœªè·å–åˆ°ä»»ä½•ç´§æ€¥æ–°é—»ï¼Œç»“æŸæœ¬æ¬¡ç›‘æ§")
            return
        
        # 2. LLMå¿«é€Ÿæƒ…ç»ªè¯„åˆ†
        analysis_result, sentiment_scores = analyze_urgent_news_with_llm(news_items)
        
        # 3. æ£€æŸ¥æ˜¯å¦è¾¾åˆ°æ¨é€é˜ˆå€¼
        if check_urgent_threshold(sentiment_scores):
            # 4. æ¨é€åˆ°é£ä¹¦
            success = send_to_feishu(analysis_result)
            if success:
                logger.info("ğŸš¨ ç´§æ€¥æ–°é—»æ¨é€å®Œæˆï¼")
            else:
                logger.error("âŒ ç´§æ€¥æ–°é—»æ¨é€å¤±è´¥")
                send_error_alert("ç´§æ€¥æ–°é—»æ¨é€å¤±è´¥ï¼Œè¯·æ£€æŸ¥é£ä¹¦åº”ç”¨é…ç½®")
        else:
            logger.info("âš ï¸ æƒ…ç»ªåˆ†æœªè¾¾åˆ°æ¨é€é˜ˆå€¼ï¼Œä¿æŒé™é»˜")
            
    except Exception as e:
        logger.exception(f"ç´§æ€¥ç›‘æ§ä¸»å‡½æ•°æ‰§è¡Œå¼‚å¸¸: {e}")
        send_error_alert(f"ç´§æ€¥ç›‘æ§æœºå™¨äººæ•…éšœï¼š{str(e)}ï¼Œè¯·ä¸»äººæ£€æŸ¥ï¼")

if __name__ == "__main__":
    main()